{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8b30f-dec7-4261-a1b8-e2b430d13280",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用Flash Attention 2.0针对注意力头进行加速推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a0b4e0-edb0-41b1-bac7-e76acde02c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.3% that image 0 is '2 cats'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import SiglipProcessor, SiglipModel\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = SiglipModel.from_pretrained(\n",
    "    \"/root/autodl-tmp/siglip-so400m-patch14-384\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device,\n",
    ")\n",
    "processor = SiglipProcessor.from_pretrained(\"/root/autodl-tmp/siglip-so400m-patch14-384\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "candidate_labels = [\"2 cats\", \"2 dogs\"]\n",
    "texts = [f'This is a photo of {label}.' for label in candidate_labels]\n",
    "inputs = processor(text=texts, images=image, padding=\"max_length\", return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.autocast(device, dtype=torch.float16):\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "logits_per_image = outputs.logits_per_image\n",
    "probs = torch.sigmoid(logits_per_image)\n",
    "print(f\"{probs[0][0]:.1%} that image 0 is '{candidate_labels[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8b2b0-400e-456b-b04d-8f913284f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyTorch包含一个原生缩放点积注意力 （SDPA） 运算符，作为 torch.nn.functional 的一部分。此功能 包含多种实现，这些实现可以根据 inputs 和使用的硬件进行应用，这里需要torch>=2.1.1才可以使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b42ce14-1bc4-490d-ae8e-69d7941ab23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.3% that image 0 is '2 cats'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import SiglipProcessor, SiglipModel\n",
    "device = \"cuda\"\n",
    "\n",
    "model = SiglipModel.from_pretrained(\n",
    "    \"/root/autodl-tmp/siglip-so400m-patch14-384\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device,\n",
    ")\n",
    "processor = SiglipProcessor.from_pretrained(\"/root/autodl-tmp/siglip-so400m-patch14-384\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "candidate_labels = [\"2 cats\", \"2 dogs\"]\n",
    "texts = [f'This is a photo of {label}.' for label in candidate_labels]\n",
    "inputs = processor(text=texts, images=image, padding=\"max_length\", return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.autocast(device, dtype=torch.float16):\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "logits_per_image = outputs.logits_per_image\n",
    "probs = torch.sigmoid(logits_per_image)\n",
    "print(f\"{probs[0][0]:.1%} that image 0 is '{candidate_labels[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd28bef-150d-44ef-b118-848cee3f9a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siglip",
   "language": "python",
   "name": "siglip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
