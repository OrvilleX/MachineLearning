# 目标检测基础知识

## 评估指标

### 准确率
首先给出准确率(Accuracy)的定义，即预测正确的结果占总样本的百分比。虽然准确率能够判断总的正确率，但是在样本不均衡的情况下，并不能作为很好的指标来衡量结果。比如在样本集中，正样本有90个，负样本有10个，样本是严重的失衡的（因为只要全部识别为正样本则准确率即为90%，这完全没有意义）。对于此类数据，完全体现不出准确率，因此，我们需要寻找新的指标来评价模型的优劣.

### 精确率
精确率(Precision)是针对预测结果而言的，其含义是在被所有预测为正的样本中实际为正样本的概率。精确率代表对正样本结果中的预测准确程度，而准确率则代表整体的预测准确程度，包括正样本和负样本.

### 召回率
召回率(Recall)是针对原样本而言的，其含义是在实际为正的样本中被预测为正样本的概率.

### 精确率与召回率示例：混淆矩阵说明
为了帮助理解精确率（Precision）与召回率（Recall）之间的关系，下面展示一个混淆矩阵示例：

|                | 预测为正（Positive） | 预测为负（Negative） |
| -------------- | -------------------- | --------------------- |
| **实际为正**   | TP                   | FN                    |
| **实际为负**   | FP                   | TN                    |

- **精确率** (Precision) = TP / (TP + FP)
- **召回率** (Recall) = TP / (TP + FN)

例如，在目标检测中，若模型设定较高的预测阈值（只在非常自信时预测为正），则可能会降低误判（False Positive），提高精确率；但与此同时可能遗漏一些实际正样本，导致召回率降低；反之，降低预测阈值则可以提高召回率，但可能引入更多误判，从而降低精确率. 这种权衡通常需要通过调节决策阈值，并综合考虑 F1 分数和 PR 曲线来达到最佳检测性能.

### 真假阴阳性定义
* TP: 是真阳性样本;
* FP: 是假阳性样本（它不是真的但模型觉得它是真的）;
* FN: 是假阴性样本（它是真的但模型觉得它是假的）

### IoU
Intersection over Union (IoU) 是衡量预测边界框与真实边界框重叠程度的指标。其计算公式为交集面积与并集面积的比值。IoU 是判断预测是否足够准确的关键指标，通常会设定一个阈值（如 0.5）来确定预测是否为正确检测.

### AP 与 mAP
Average Precision (AP) 衡量单个类别检测精度，是基于精确率和召回率曲线计算得到的积分值。而 mean Average Precision (mAP) 则是所有类别 AP 的平均值，是评估目标检测整体性能的重要指标.

## 模型优化与训练策略

### 算法收敛性
算法的收敛性就是指某个算法能否在迭代时间趋于无穷的假设下，最终找到问题的全局最优解。这里有一点要明确：算法收敛性是迭代法中的一个概念，所以主要针对与迭代相关的算法，如进化算法。对于能够一次求解的直接法，就不在算法收敛的讨论范围之内了.

仅仅知道算法是收敛的还远远不够，收敛性的结论是建立在无穷迭代时间基础上的，而实际应用中的计算迭代时间是有限的。收敛性研究只能回答进化算法在迭代无穷次后最终会不会找到全局最优解，而不能回答算法实际究竟要花多长时间（迭代多少次）才能找到最优解，很难在实践中用于指导算法设计和改进.

在目标检测任务中，算法收敛性与模型训练过程密切相关。虽然理论上关注的是算法在无限迭代下是否能达到全局最优，在实际应用中，我们更关注训练过程中损失函数（loss）的下降趋势以及验证集上性能指标（如 mAP）的稳定性。这些实际观测指标帮助判断模型是否已经收敛，并指导采用早停策略（early stopping）或动态调整学习率（learning rate schedules），以在有限迭代次数内达到较优的检测效果.

### 算法收敛速度
算法收敛速度就是指算法需要经过多少次迭代才能得到最优解。很明显，有些算法收敛性好，有些则不尽相同，所谓收敛性好就是收敛得快，快速收敛的意义在于使用较少的迭代次数便可获得相对精确的值，或者在允许的时间内得到满意结果。因此，能以较快速度收敛于最优解的算法，才能称得上一个好算法.

### 学习率与训练轮次
两者存在密切的关系，对于深度学习模型的训练至关重要。关于两者参数的具体说明如下：

* 学习率：控制模型权重更新步长的参数，它决定了模型在每次迭代中对梯度下降的响应程度。较小的学习率可能导致训练收敛缓慢，而过大的学习率可能使模型发散.
* 训练轮次（Epochs）：代表整个训练数据集被模型使用的一次。轮次数量影响模型对数据的观察次数，更多轮次可能有助于学习特征，但过多则可能导致过拟合.

### 回归损失与分类损失
在目标检测任务中，损失函数通常由两部分组成：
* 回归损失：用于度量预测边界框与真实边界框之间的位置偏差（如 L1 或 L2 损失）.
* 分类损失：用于衡量预测类别概率与真实类别之间的差距（如交叉熵损失）.
同时优化这两部分损失可以使模型更准确地定位目标并进行正确分类.

## 检测模型关键组件

### Anchor
Anchor（或称 Anchor Boxes）是预先定义的一组候选检测框，具有不同的尺度和纵横比。在目标检测网络中，通过对 Anchor 框进行位置和尺寸的回归调整，使其更贴合目标，从而提高检测精度.

### Confidence Score
Confidence Score 表示预测边界框中存在目标的置信度。它通常结合分类概率和边界框回归信息，反映模型对于该候选框是否包含目标的信心，是筛选高质量检测结果的重要依据.

## 卷积层面

### 空洞卷积（Dilated Convolution）

空洞卷积也叫扩张卷积或膨胀卷积，简单来说就是在卷积核元素之间加入一些空格来扩大卷积核的过程，与常规卷积相比具备更大的感受野.

![空洞卷积](/media/cilated_convolution.png)

建设以变量a来衡量空洞卷积的扩张系数，则加入空洞之后的实际卷积核尺寸与原始卷积核尺寸之间的关系：K = K + (k-1)(a-1)。其实感受野还有一点比较重要的是，对于一个卷积特征图而言，感受野中每个像素并不是同等重要的，越接近感受野中间的像素相对而言就越重要.

空洞卷积主要有三个作用：
* 扩大感受野。但需要明确一点，池化也可以扩大感受野，但空间分辨率降低了，相比之下，空洞卷积可以在扩大感受野的同时不丢失分辨率，且保持像素的相对空间位置不变。简单而言，空洞卷积可以同时控制感受野和分辨率.
* 获取多尺度上下文信息。当多个带有不同 dilation rate 的空洞卷积核叠加时，不同的感受野会带来多尺度信息，这对于分割任务非常重要.
* 可以降低计算量，不需要引入额外的参数，如上图所示，实际卷积时只有带有红点的元素真正参与计算.
