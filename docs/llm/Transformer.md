# Transformer模型基础知识

## 一、关键部分

有两个关键思想对Transformer模型的发展做出了贡献。第一个是自我监督，第二个就是自我注意。关于这两个关键
部分的介绍，将在后面的章节中进行详细的介绍。  

### 1.1 自监督学习（Self-Supervision）

通常指的是自监督学习（Self-Supervised Learning, SSL），这是一种机器学习方法，特别是在深度学习和自
然语言处理（NLP）领域中。在这个背景下，自监督学习是一种无需或减少人工标注数据即可训练模型的方法。  

#### 1.1.1 主要用途  

* `预训练大型模型`：自监督学习使得可以在大规模未标注数据上预训练模型。这种预训练通常在语言模型
（如BERT、GPT）中使用，以学习丰富的语言表示;
* `特征提取`：通过自监督学习，模型能够学习到数据的深层次特征，这些特征对于理解语言的复杂性至关重要;  
* `提高泛化能力`：自监督学习训练的模型通常具有更好的泛化能力，能够在多种下游任务上表现良好，如文本
分类、情感分析、问答系统等;  
* `减少对标注数据的依赖`：自监督学习减少了对大量标注数据的需求，这对于资源受限的语言或领域特别有价值;  

#### 1.1.2 具体原理

* `数据预处理`：在自监督学习中，模型使用未标注的数据。例如，可以使用大量的文本数据进行训练;  
* `生成伪标签`：自监督学习通过从输入数据本身生成伪标签来构建训练任务。例如，在NLP中，一个
常见的方法是掩码语言模型（MLM），其中模型预测文本中随机掩盖的单词;  
* `Transformer架构`：Transformer模型利用自注意力机制（Self-Attention）来处理序列数
据。这允许模型在处理一个元素（如单词）时，考虑到序列中的所有其他元素，从而更好地理解上下文和语言结构;  
* `上下文理解`：通过自监督学习，Transformer模型能够捕捉到词汇、短语和句子级别的上下文信息，这对于
理解语言的意图和含义至关重要;  
* `微调`：预训练完成后，模型可以在特定的下游任务上进行微调。这通常涉及在有限的标注数据上进行额外的训
练，以使模型适应特定任务的需求;  

#### 1.1.3 任务设计

对于自监督学习中，任务设计是核心组成部分，尤其是在处理如文本、图像等数据时。这些任务被设计为使模型能够
从数据汇总自动提取有用的特征，而无需依赖外部标注。以下是一些任务设计的方式：  
------
文本数据

* `掩码语言模型（Masked Language Modeling, MLM）`： 如BERT模型所采用的方法，随机掩盖文本中的某
些词汇（例如，将它们替换为一个特殊的[MASK]标记），然后训练模型预测这些掩盖的词汇;  
* `下一个词预测（Next Word Prediction）`： 如GPT系列模型所用，模型被训练来预测给定文本序列中的下一个词汇;  
* `句子顺序预测（Sentence Order Prediction）`： 训练模型来判断两个句子是否按照正确的顺序排列，这有助于模型学习理解句子间的关系和逻辑流;  

------
图像数据

* `图像重建（Image Reconstruction）`： 模型从部分遮蔽或损坏的图像中重建原始图像。这要求模型理解图像的整体结构和内容;  
* `对比学习（Contrastive Learning）`： 通过比较不同的图像（或同一图像的不同视图），模型学习区分不同的对象或场景;  
* `颜色化（Colorization）`： 从黑白图像生成彩色版本，这要求模型理解物体的真实颜色和场景的上下文;  

------
音频数据

* `下一个样本预测（Next Sample Prediction）`： 类似于文本中的下一个词预测，模型预测音频序列中的下一个样本;  
* `音频填充（Audio Inpainting）`： 从部分遮蔽的音频信号中重建丢失的部分，要求模型理解音频的上下文和结构;  

------
通用方法  

* `对抗性训练（Adversarial Training）`： 使用生成对抗网络（GAN）中的思想，模型学习生成数据，同时另一个模型
学习区分真实数据和生成数据;  
* `自监督聚类（Self-Supervised Clustering）`： 模型被训练来对数据进行聚类，以发现潜在的结构或模式;

### 1.2 自注意力机制（Self-Attention Mechanism）

自注意力（Self-Attention）是一种让计算机模型理解和处理像文本这样的序列数据的技术。可以把它想象成阅读时的过程：当
你读到一个句子中的某个词时，你的大脑不仅考虑这个词本身，还会考虑它与句子中其他词的关系。自注意力就是这样工作的，它帮
助模型在处理一个词（或数据点）时，同时考虑到整个句子（或序列）中的所有词，从而更好地理解每个词的意义和它们之间的联系。这
种方法使得模型能够捕捉到复杂的上下文信息，对于理解和生成语言非常有效。  

#### 1.2.1 主要用途

* `上下文感知的特征表示`： 自注意力使模型能够为序列中的每个元素（如单词）生成考虑了整个序列上下文的表示。这对于理解 
语言中的复杂性和细微差别至关重要;  
* `长距离依赖捕捉`： 在处理长文本时，自注意力能够有效地捕捉远距离的依赖关系，这是传统的循环神经网络（RNN）难以做到的;  
* `并行处理`： 自注意力允许模型并行处理序列中的所有元素，从而提高了计算效率，特别是在处理长序列时;  
* `多任务学习`： 在Transformer架构中，自注意力使得模型能够在多种任务上表现出色，如文本分类、机器翻译、问答系统等;

#### 1.2.2 具体原理

* `计算注意力分数`： 对于序列中的每个元素，模型计算其与序列中所有其他元素的注意力分数。这些分数表示元素之间的相关性;  
* `三个关键向量`： 每个元素都被表示为三个向量：查询（Query）、键（Key）和值（Value）。这些向量通过训练学习得到。 注意力分数是通过查询向量与对应的键向量的点积来计算的;  
* `缩放点积注意力`： 计算得到的分数通常会进行缩放处理，然后通过softmax函数转换为概率分布;  
* `加权值向量`： 每个元素的输出是其所有值向量的加权和，权重由注意力分数决定;  
* `多头注意力`： 在实际应用中，通常使用多头注意力机制，即并行地执行多个自注意力操作，每个操作关注不同的表示子空间。这增加了模型捕捉不同类型信息的能力;  

#### 1.2.3 额外注意

------
多头注意力  

* `理解词与词之间的关系`： 比如文章中有句话：“猫坐在垫子上。”一个“头”可能专注于“猫”和“坐”之间的动作关系，而另一个“头”可能探索“垫子”和“坐”的空间
关系。这就像是你在阅读时不仅理解每个词的意思，还要理解它们是如何相互关联的;  
* `捕捉语境的不同方面`： 在一篇关于历史的文章中，一个“头”可能专注于时间线索（如日期和事件），另一个“头”可能关注人物和地点。这就像是你在阅读历史文
章时，既要理解事件的时间顺序，也要了解关键人物和地点;  
* `处理复杂句子结构`： 对于一个长句子，不同的“头”可以帮助模型理解句子的不同成分，比如主语、谓语和宾语。这有点像是在阅读一个长句子时，你会分别关注
句子的主要部分和它们是如何组合在一起的;  
* `理解隐含意义`： 在处理比喻或隐喻时，不同的“头”可以帮助模型从字面意义和隐含意义中提取信息。例如，如果文章说“时间是一条河流”，一个“头”可能理
解“时间”和“河流”的直接联系，而另一个“头”可能探索这种比喻背后的深层含义;  

------
针对计算注意力分数、三个关键向量与缩放点积注意力的简单理解  

想象你在一个聚会上，你想了解每个人对其他人的看法。这个场景可以帮助我们理解自注意力机制的工作原理。

① `三个关键向量（查询、键、值）`：  
* `查询（Query）`：这就像是你对聚会上的一个人（比如Bob）提出的问题，“你对Alice有什么看法？”这里，Bob是你的“查询”对象。
* `键（Key）`：这代表着其他人（比如Alice）在这个问题中的角色。Alice是你想了解的对象，所以她是“键”。
* `值（Value）`：这是Bob对Alice的看法或回答。Bob对Alice的回答是“值”，它提供了关于Alice的信息。

② `计算注意力分数`：  
这就像是衡量Bob的回答有多重要或相关。如果Bob和Alice很亲近，那么他的回答（值）就更重要，所以注意力分数更高。

③ `缩放点积注意力`：  
在实际计算中，为了避免数值过大，我们会对注意力分数进行缩放（比如除以一个常数）。这就像是在处理很多人的回答时，为了避免某些回答过于突出，我们会稍微调整它们的重要性。

## Positional Encoding位置编码

在任何一门语言中，词语的位置和顺序对句子意思表达都是至关重要的。传统的RNN模型在处理句子时，以序列的模式逐个处理
句子中的词语，这使得词语的顺序信息在处理过程中被天然的保存下来了，并不需要额外的处理。 而对于Transformer来说，由
于句子中的词语都是同时进入网络进行处理，顺序信息在输入网络时就已丢失。因此，Transformer是需要额外的处理来告知每个
词语的相对位置的。其中的一个解决方案，就是论文中提到的Positional Encoding，将能表示位置信息的编码添加到输入中，让
网络知道每个词的位置和顺序。  

一句话概括，Positional Encoding就是句子中词语相对位置的编码，让Transformer保留词语的位置信息。

### 参考文章
* [一文教你彻底理解Transformer中Positional Encoding](https://zhuanlan.zhihu.com/p/338592312)  
* [Transformer学习笔记一：Positional Encoding（位置编码）](https://zhuanlan.zhihu.com/p/454482273)

## Object Queries

Object queries有N个（其中N是一个事先设定的、比远远大于image中object个数的一个整数），输入Transformer Decoder后分别得到 
N个decoder output embedding，经过FFN（后面会讲）处理后就得到了 N个预测的boxes和这些boxes的类别。 具体实现上，object qu
eries是N个learnable embedding，训练刚开始时可以随机初始化。在训练过程中，因为需要生成不同的boxes，object queries会被迫使
变得不同来反映位置信息，所以也可以称为leant positional encoding （注意和encoder中讲的position encoding区分，不是一个东西）。  

### 参考文章
* [用Transformer做object detection：DETR](https://zhuanlan.zhihu.com/p/267156624)  
* [Object query的理解](https://blog.csdn.net/wzk4869/article/details/129908100)  
* [Transformer在目标检测领域的开山之作DETR模型](https://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&mid=2247585078&idx=1&sn=acf1b094e7b32fb82807e32267154445&chksm=96f1ff62a1867674b49f3b9040444e92a09b986b40ee2d72030ec21c773e6f6f39f585f08343&scene=27)  
* [通往数据高效的Transformer目标检测器](https://www.cvmart.net/community/detail/6615)  